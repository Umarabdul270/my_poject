{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 113485,
          "databundleVersionId": 13542141,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "DSN AI Bootcamp",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Umarabdul270/my_poject/blob/master/DSN_AI_Bootcamp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()"
      ],
      "metadata": {
        "id": "8KlAXRJ8RRi0"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "hackathon_qualification_path = kagglehub.competition_download('hackathon-qualification')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "t6YyZ_yiRRi4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-04T22:47:26.194624Z",
          "iopub.execute_input": "2025-09-04T22:47:26.195299Z",
          "iopub.status.idle": "2025-09-04T22:47:26.210189Z",
          "shell.execute_reply.started": "2025-09-04T22:47:26.19526Z",
          "shell.execute_reply": "2025-09-04T22:47:26.209099Z"
        },
        "id": "235DtrT1RRi7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing requirement modules"
      ],
      "metadata": {
        "id": "FVRzbgzLRRi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-04T22:47:26.211963Z",
          "iopub.execute_input": "2025-09-04T22:47:26.21232Z",
          "iopub.status.idle": "2025-09-04T22:47:26.240616Z",
          "shell.execute_reply.started": "2025-09-04T22:47:26.212294Z",
          "shell.execute_reply": "2025-09-04T22:47:26.239486Z"
        },
        "id": "cHC7xmJ8RRjB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data frame"
      ],
      "metadata": {
        "id": "u8fLkZtdRRjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/kaggle/input/hackathon-qualification/archive/train.csv\"\n",
        "test_path = \"/kaggle/input/hackathon-qualification/archive/test.csv\"\n",
        "submission_path = \"/kaggle/input/hackathon-qualification/archive/sample_submission.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "submission_df = pd.read_csv(submission_path)\n",
        "\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape:\", test_df.shape)\n",
        "print(\"Submission shape:\", submission_df.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-04T22:47:26.372979Z",
          "iopub.execute_input": "2025-09-04T22:47:26.373462Z",
          "iopub.status.idle": "2025-09-04T22:47:27.15383Z",
          "shell.execute_reply.started": "2025-09-04T22:47:26.373423Z",
          "shell.execute_reply": "2025-09-04T22:47:27.152821Z"
        },
        "id": "kPQhKN3YRRjF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding the data frame"
      ],
      "metadata": {
        "id": "BfXU6ZAzRRjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(10)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-04T22:47:27.155128Z",
          "iopub.execute_input": "2025-09-04T22:47:27.155478Z",
          "iopub.status.idle": "2025-09-04T22:47:27.180617Z",
          "shell.execute_reply.started": "2025-09-04T22:47:27.15545Z",
          "shell.execute_reply": "2025-09-04T22:47:27.179489Z"
        },
        "id": "VbHmoQUsRRjJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.tail()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-04T22:47:27.181727Z",
          "iopub.execute_input": "2025-09-04T22:47:27.182096Z",
          "iopub.status.idle": "2025-09-04T22:47:27.198779Z",
          "shell.execute_reply.started": "2025-09-04T22:47:27.182054Z",
          "shell.execute_reply": "2025-09-04T22:47:27.197356Z"
        },
        "id": "TLKJLN-VRRjL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-04T22:47:27.20094Z",
          "iopub.execute_input": "2025-09-04T22:47:27.20149Z",
          "iopub.status.idle": "2025-09-04T22:47:27.311958Z",
          "shell.execute_reply.started": "2025-09-04T22:47:27.201462Z",
          "shell.execute_reply": "2025-09-04T22:47:27.31047Z"
        },
        "id": "3noYf9QhRRjN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for empty cells\n",
        "train_df.isna().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-04T22:47:27.312822Z",
          "iopub.execute_input": "2025-09-04T22:47:27.31309Z",
          "iopub.status.idle": "2025-09-04T22:47:27.40159Z",
          "shell.execute_reply.started": "2025-09-04T22:47:27.313067Z",
          "shell.execute_reply": "2025-09-04T22:47:27.400369Z"
        },
        "id": "Eb5nxJ6mRRjO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"brand\"]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-04T22:47:27.40243Z",
          "iopub.execute_input": "2025-09-04T22:47:27.402751Z",
          "iopub.status.idle": "2025-09-04T22:47:27.419319Z",
          "shell.execute_reply.started": "2025-09-04T22:47:27.40273Z",
          "shell.execute_reply": "2025-09-04T22:47:27.418452Z"
        },
        "id": "LR5xsWWXRRjQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6tJ6ya3yRRjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix = predictor.X.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap of Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-04T23:15:47.055148Z",
          "iopub.execute_input": "2025-09-04T23:15:47.056068Z",
          "iopub.status.idle": "2025-09-04T23:15:48.20237Z",
          "shell.execute_reply.started": "2025-09-04T23:15:47.056037Z",
          "shell.execute_reply": "2025-09-04T23:15:48.201239Z"
        },
        "id": "mLPw-AOiRRjS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Improved Car Price Prediction Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import joblib\n",
        "import re\n",
        "\n",
        "class CarPricePredictor:\n",
        "    def __init__(self):\n",
        "        self.label_encoders = {}\n",
        "        self.feature_columns = None\n",
        "        self.models = {}\n",
        "        self.best_model = None\n",
        "        self.scaler = None\n",
        "\n",
        "    def load_data(self, train_path, test_path):\n",
        "        \"\"\"Load training and test datasets\"\"\"\n",
        "        try:\n",
        "            self.train_df = pd.read_csv(train_path)\n",
        "            self.test_df = pd.read_csv(test_path)\n",
        "            print(f\"âœ“ Training data loaded: {self.train_df.shape}\")\n",
        "            print(f\"âœ“ Test data loaded: {self.test_df.shape}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"âœ— Error loading data: {e}\")\n",
        "            return False\n",
        "\n",
        "    def exploratory_analysis(self):\n",
        "        \"\"\"Comprehensive EDA\"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Basic info\n",
        "        print(\"\\nðŸ“Š Dataset Overview:\")\n",
        "        print(f\"Training samples: {len(self.train_df)}\")\n",
        "        print(f\"Features: {len(self.train_df.columns)-1}\")\n",
        "        print(f\"Target: price\")\n",
        "\n",
        "        # Missing values analysis\n",
        "        print(\"\\nðŸ” Missing Values Analysis:\")\n",
        "        missing_train = self.train_df.isnull().sum()\n",
        "        missing_test = self.test_df.isnull().sum()\n",
        "\n",
        "        missing_df = pd.DataFrame({\n",
        "            'Train_Missing': missing_train,\n",
        "            'Train_Percent': (missing_train / len(self.train_df)) * 100,\n",
        "            'Test_Missing': missing_test,\n",
        "            'Test_Percent': (missing_test / len(self.test_df)) * 100\n",
        "        })\n",
        "        print(missing_df[missing_df['Train_Missing'] > 0])\n",
        "\n",
        "        # Target variable analysis\n",
        "        print(f\"\\nðŸŽ¯ Target Variable Statistics:\")\n",
        "        print(f\"Mean price: ${self.train_df['price'].mean():,.2f}\")\n",
        "        print(f\"Median price: ${self.train_df['price'].median():,.2f}\")\n",
        "        print(f\"Price range: ${self.train_df['price'].min():,.2f} - ${self.train_df['price'].max():,.2f}\")\n",
        "\n",
        "        # Outlier detection\n",
        "        Q1 = self.train_df['price'].quantile(0.25)\n",
        "        Q3 = self.train_df['price'].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        outliers = len(self.train_df[(self.train_df['price'] < Q1 - 1.5*IQR) |\n",
        "                                   (self.train_df['price'] > Q3 + 1.5*IQR)])\n",
        "        print(f\"Price outliers detected: {outliers} ({outliers/len(self.train_df)*100:.1f}%)\")\n",
        "\n",
        "        self._plot_distributions()\n",
        "\n",
        "    def _plot_distributions(self):\n",
        "        \"\"\"Create visualization plots\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "        # Price distribution\n",
        "        sns.histplot(data=self.train_df, x='price', kde=True, ax=axes[0,0])\n",
        "        axes[0,0].set_title('Price Distribution')\n",
        "        axes[0,0].set_xlabel('Price ($)')\n",
        "\n",
        "        # Log price distribution (to handle skewness)\n",
        "        sns.histplot(data=self.train_df, x=np.log1p(self.train_df['price']), kde=True, ax=axes[0,1])\n",
        "        axes[0,1].set_title('Log Price Distribution')\n",
        "        axes[0,1].set_xlabel('Log(Price + 1)')\n",
        "\n",
        "        # Price vs Year\n",
        "        sns.scatterplot(data=self.train_df, x='model_year', y='price', alpha=0.5, ax=axes[1,0])\n",
        "        axes[1,0].set_title('Price vs Model Year')\n",
        "\n",
        "        # Price vs Mileage\n",
        "        sns.scatterplot(data=self.train_df, x='milage', y='price', alpha=0.5, ax=axes[1,1])\n",
        "        axes[1,1].set_title('Price vs Mileage')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def feature_engineering(self, df, is_train=True):\n",
        "        \"\"\"Advanced feature engineering\"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # Age of car\n",
        "        current_year = 2024\n",
        "        df['car_age'] = current_year - df['model_year']\n",
        "\n",
        "        # Extract horsepower from engine description\n",
        "        def extract_horsepower(engine_str):\n",
        "            if pd.isna(engine_str):\n",
        "                return 0\n",
        "            match = re.search(r'(\\d+\\.?\\d*)HP', str(engine_str))\n",
        "            return float(match.group(1)) if match else 0\n",
        "\n",
        "        df['horsepower'] = df['engine'].apply(extract_horsepower)\n",
        "\n",
        "        # Extract engine displacement\n",
        "        def extract_displacement(engine_str):\n",
        "            if pd.isna(engine_str):\n",
        "                return 0\n",
        "            match = re.search(r'(\\d+\\.?\\d*)L', str(engine_str))\n",
        "            return float(match.group(1)) if match else 0\n",
        "\n",
        "        df['displacement'] = df['engine'].apply(extract_displacement)\n",
        "\n",
        "        # Power to weight ratio (approximation using displacement)\n",
        "        df['power_per_liter'] = df['horsepower'] / (df['displacement'] + 1)\n",
        "\n",
        "        # Mileage per year\n",
        "        df['mileage_per_year'] = df['milage'] / (df['car_age'] + 1)\n",
        "\n",
        "        # Brand value categories (based on luxury/economy segments)\n",
        "        luxury_brands = ['Mercedes-Benz', 'BMW', 'Audi', 'Lexus', 'Porsche', 'Tesla', 'Genesis']\n",
        "        premium_brands = ['Acura', 'Infiniti', 'Cadillac', 'Lincoln', 'Volvo']\n",
        "\n",
        "        df['brand_category'] = df['brand'].apply(lambda x:\n",
        "            'Luxury' if x in luxury_brands else\n",
        "            'Premium' if x in premium_brands else 'Standard')\n",
        "\n",
        "        return df\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        \"\"\"Robust preprocessing pipeline\"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"PREPROCESSING DATA\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Apply feature engineering\n",
        "        print(\"ðŸ”§ Applying feature engineering...\")\n",
        "        self.train_processed = self.feature_engineering(self.train_df, is_train=True)\n",
        "        self.test_processed = self.feature_engineering(self.test_df, is_train=False)\n",
        "\n",
        "        # Handle missing values strategically\n",
        "        print(\"ðŸ”§ Handling missing values...\")\n",
        "        self._handle_missing_values()\n",
        "\n",
        "        # Encode categorical variables\n",
        "        print(\"ðŸ”§ Encoding categorical variables...\")\n",
        "        self._encode_categorical_variables()\n",
        "\n",
        "        # Remove outliers from training data\n",
        "        print(\"ðŸ”§ Handling outliers...\")\n",
        "        self._handle_outliers()\n",
        "\n",
        "        # Prepare features\n",
        "        print(\"ðŸ”§ Preparing final feature set...\")\n",
        "        self._prepare_features()\n",
        "\n",
        "        print(\"âœ“ Preprocessing completed!\")\n",
        "\n",
        "    def _handle_missing_values(self):\n",
        "        \"\"\"Strategic missing value handling\"\"\"\n",
        "        # Numerical columns - use median\n",
        "        numerical_cols = ['model_year', 'milage', 'horsepower', 'displacement']\n",
        "        for col in numerical_cols:\n",
        "            if col in self.train_processed.columns:\n",
        "                median_val = self.train_processed[col].median()\n",
        "                self.train_processed[col].fillna(median_val, inplace=True)\n",
        "                self.test_processed[col].fillna(median_val, inplace=True)\n",
        "\n",
        "        # Categorical columns - use mode or specific logic\n",
        "        categorical_cols = ['fuel_type', 'accident', 'clean_title']\n",
        "        for col in categorical_cols:\n",
        "            if col in self.train_processed.columns:\n",
        "                if col == 'accident':\n",
        "                    # For accident, missing likely means no accident\n",
        "                    self.train_processed[col].fillna('None reported', inplace=True)\n",
        "                    self.test_processed[col].fillna('None reported', inplace=True)\n",
        "                elif col == 'clean_title':\n",
        "                    # For clean_title, missing is ambiguous, use most common\n",
        "                    mode_val = self.train_processed[col].mode()[0] if len(self.train_processed[col].mode()) > 0 else 'Yes'\n",
        "                    self.train_processed[col].fillna(mode_val, inplace=True)\n",
        "                    self.test_processed[col].fillna(mode_val, inplace=True)\n",
        "                else:\n",
        "                    mode_val = self.train_processed[col].mode()[0] if len(self.train_processed[col].mode()) > 0 else 'Unknown'\n",
        "                    self.train_processed[col].fillna(mode_val, inplace=True)\n",
        "                    self.test_processed[col].fillna(mode_val, inplace=True)\n",
        "\n",
        "    def _encode_categorical_variables(self):\n",
        "        \"\"\"Consistent categorical encoding\"\"\"\n",
        "        categorical_cols = self.train_processed.select_dtypes(include='object').columns\n",
        "        categorical_cols = [col for col in categorical_cols if col != 'price']\n",
        "\n",
        "        for col in categorical_cols:\n",
        "            le = LabelEncoder()\n",
        "\n",
        "            # Combine train and test for consistent encoding\n",
        "            combined_values = pd.concat([self.train_processed[col], self.test_processed[col]]).astype(str)\n",
        "            le.fit(combined_values)\n",
        "\n",
        "            self.train_processed[col] = le.transform(self.train_processed[col].astype(str))\n",
        "            self.test_processed[col] = le.transform(self.test_processed[col].astype(str))\n",
        "\n",
        "            self.label_encoders[col] = le\n",
        "\n",
        "    def _handle_outliers(self):\n",
        "        \"\"\"Remove extreme outliers from training data\"\"\"\n",
        "        # Price outliers\n",
        "        Q1 = self.train_processed['price'].quantile(0.01)\n",
        "        Q99 = self.train_processed['price'].quantile(0.99)\n",
        "\n",
        "        initial_size = len(self.train_processed)\n",
        "        self.train_processed = self.train_processed[\n",
        "            (self.train_processed['price'] >= Q1) &\n",
        "            (self.train_processed['price'] <= Q99)\n",
        "        ]\n",
        "        removed = initial_size - len(self.train_processed)\n",
        "        print(f\"   Removed {removed} extreme price outliers ({removed/initial_size*100:.1f}%)\")\n",
        "\n",
        "        # Mileage outliers\n",
        "        Q99_mileage = self.train_processed['milage'].quantile(0.99)\n",
        "        self.train_processed = self.train_processed\n",
        "        [self.train_processed['milage'] <= Q99_mileage]\n",
        "        print(self.train_processed.head(10))\n",
        "\n",
        "    def _prepare_features(self):\n",
        "        \"\"\"Prepare final feature matrix\"\"\"\n",
        "        # Define feature columns (exclude target and id)\n",
        "        exclude_cols = ['id', 'price'] if 'price' in self.train_processed.columns else ['id']\n",
        "        self.feature_columns = [col for col in self.train_processed.columns if col not in exclude_cols]\n",
        "\n",
        "        # Prepare training data\n",
        "        self.X = self.train_processed[self.feature_columns]\n",
        "        self.y = self.train_processed['price']\n",
        "\n",
        "        # Prepare test data\n",
        "        self.X_test = self.test_processed[self.feature_columns]\n",
        "\n",
        "        print(f\"   Final feature set: {len(self.feature_columns)} features\")\n",
        "        print(f\"   Training samples after cleaning: {len(self.X)}\")\n",
        "\n",
        "    def train_models(self):\n",
        "        \"\"\"Train a Linear Regression model\"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"MODEL TRAINING\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Split training data\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            self.X, self.y, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        # Define the model\n",
        "        model = LinearRegression()\n",
        "\n",
        "        print(\"\\nðŸš€ Training Linear Regression...\")\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Validate\n",
        "        y_pred = model.predict(X_val)\n",
        "\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "        r2 = r2_score(y_val, y_pred)\n",
        "        mae = mean_absolute_error(y_val, y_pred)\n",
        "\n",
        "        self.best_model = model\n",
        "        self.models = {'LinearRegression': {'model': model, 'rmse': rmse}}\n",
        "\n",
        "        print(f\"   âœ“ RMSE: ${rmse:,.2f}\")\n",
        "\n",
        "        # Retrain on full dataset\n",
        "        print(\"\\nðŸ”„ Retraining best model on full dataset...\")\n",
        "        self.best_model.fit(self.X, self.y)\n",
        "\n",
        "        return self.models\n",
        "\n",
        "    def analyze_feature_importance(self):\n",
        "        \"\"\"Analyze and visualize feature importance\"\"\"\n",
        "        if hasattr(self.best_model, 'coef_'):\n",
        "            importances = self.best_model.coef_\n",
        "            feature_importance = pd.DataFrame({\n",
        "                'feature': self.feature_columns,\n",
        "                'importance': np.abs(importances) # Use absolute value for linear models\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            print(\"\\nðŸ“Š Top 10 Most Important Features (Absolute Coefficient):\")\n",
        "            print(feature_importance.head(10).to_string(index=False))\n",
        "\n",
        "            # Plot feature importance\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
        "            plt.title('Feature Importance (Absolute Coefficient)')\n",
        "            plt.xlabel('Absolute Coefficient Value')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            return feature_importance\n",
        "        else:\n",
        "            print(\"âš ï¸  Feature importance not available for this model type\")\n",
        "            return None\n",
        "\n",
        "    def generate_predictions(self):\n",
        "        \"\"\"Generate predictions for test set\"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"GENERATING PREDICTIONS\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = self.best_model.predict(self.X_test)\n",
        "\n",
        "        # Create submission DataFrame\n",
        "        submission = pd.DataFrame({\n",
        "            'id': self.test_df['id'],\n",
        "            'price': predictions\n",
        "        })\n",
        "\n",
        "        print(f\"âœ“ Generated {len(predictions)} predictions\")\n",
        "        print(f\"âœ“ Prediction range: ${predictions.min():,.2f} - ${predictions.max():,.2f}\")\n",
        "        print(f\"âœ“ Mean prediction: ${predictions.mean():,.2f}\")\n",
        "\n",
        "        return submission\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        \"\"\"Save the trained model\"\"\"\n",
        "        model_data = {\n",
        "            'model': self.best_model,\n",
        "            'feature_columns': self.feature_columns,\n",
        "            'label_encoders': self.label_encoders\n",
        "        }\n",
        "        joblib.dump(model_data, filepath)\n",
        "        print(f\"âœ“ Model saved to {filepath}\")\n",
        "\n",
        "# Usage Example\n",
        "def main():\n",
        "    # Initialize predictor\n",
        "    predictor = CarPricePredictor()\n",
        "\n",
        "    # Load data\n",
        "    if not predictor.load_data('/kaggle/input/hackathon-qualification/archive/train.csv'\n",
        "                               ,'/kaggle/input/hackathon-qualification/archive/test.csv'):\n",
        "        return\n",
        "\n",
        "    # Exploratory analysis\n",
        "    predictor.exploratory_analysis()\n",
        "\n",
        "    # Preprocess data\n",
        "    predictor.preprocess_data()\n",
        "\n",
        "    # Train models\n",
        "    results = predictor.train_models()\n",
        "\n",
        "    # Analyze feature importance\n",
        "    feature_importance = predictor.analyze_feature_importance()\n",
        "\n",
        "    # Generate predictions\n",
        "    submission = predictor.generate_predictions()\n",
        "\n",
        "    # Save results\n",
        "    submission.to_csv('submission.csv', index=False)\n",
        "    print(\"\\nâœ… Submission file created: submission.csv\")\n",
        "\n",
        "    # Save model\n",
        "    predictor.save_model('car_price_model.joblib')\n",
        "\n",
        "    return predictor, submission\n",
        "\n",
        "# Run the improved pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    predictor, submission = main()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-04T23:06:44.783952Z",
          "iopub.execute_input": "2025-09-04T23:06:44.784325Z",
          "iopub.status.idle": "2025-09-04T23:06:54.579893Z",
          "shell.execute_reply.started": "2025-09-04T23:06:44.784303Z",
          "shell.execute_reply": "2025-09-04T23:06:54.578908Z"
        },
        "id": "6gElsW7NRRjS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    submission_df = pd.read_csv('submission.csv')\n",
        "    print(\"Contents of submission.csv:\")\n",
        "    display(submission_df)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: submission.csv not found. Please make sure you have run the code to generate the submission file.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading submission.csv: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-04T23:08:16.621929Z",
          "iopub.execute_input": "2025-09-04T23:08:16.622232Z",
          "iopub.status.idle": "2025-09-04T23:08:16.6658Z",
          "shell.execute_reply.started": "2025-09-04T23:08:16.62221Z",
          "shell.execute_reply": "2025-09-04T23:08:16.664552Z"
        },
        "id": "YovHKBoNRRjX"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}